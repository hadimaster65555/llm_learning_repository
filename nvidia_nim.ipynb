{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68efe1ad-af26-4fee-b9f0-c24cc46216fe",
   "metadata": {},
   "source": [
    "# Create Agent using NVIDIA NIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b399262-3f15-4568-bf7b-5524a3dd9f8d",
   "metadata": {},
   "source": [
    "Here I build simple agent that call goweather.xyz API to measure temperature given city name by leveraging LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b20b28-18ca-4cb7-8b36-0ba2ad16c294",
   "metadata": {},
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd1eae6-e447-4962-b68f-fded67435e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebfb26f-6c3d-46bb-8860-b15d6a55c697",
   "metadata": {},
   "source": [
    "# Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d00152-8340-4810-95a7-5e7f7062bc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load config inside .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12457b4a-0569-47e4-b53b-0c1c47039706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NVIDIA_API_KEY\n",
    "# os.environ[\"NVIDIA_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac43b39-541b-4d22-bcc2-44ae152dc522",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ad6549-b1e1-4f6b-9b7d-9031deca0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "llm = ChatNVIDIA(model=\"nvidia/llama-3.1-nemotron-nano-4b-v1.1\", max_completion_tokens=419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ee4dd6-887e-4311-be92-b5abd33608f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all supported model, uncomment script below to check\n",
    "# [model.id for model in llm.available_models if model.model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0205925-7c78-400b-91e2-a707469d8152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='qwen/qwq-32b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=True, base_model=None),\n",
       " Model(id='nvidia/llama-3.1-nemotron-ultra-253b-v1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=True, base_model=None),\n",
       " Model(id='meta/llama-3.1-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='qwen/qwen3-next-80b-a3b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='nvidia/llama-3.1-nemotron-nano-4b-v1.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=True, base_model=None),\n",
       " Model(id='nvidia/llama-3.3-nemotron-super-49b-v1.5', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=True, base_model=None),\n",
       " Model(id='qwen/qwen3-235b-a22b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=True, base_model=None),\n",
       " Model(id='openai/gpt-oss-20b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='bytedance/seed-oss-36b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=True, base_model=None),\n",
       " Model(id='mistralai/mistral-nemotron', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=False, base_model=None),\n",
       " Model(id='deepseek-ai/deepseek-r1-0528', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=False, base_model=None),\n",
       " Model(id='meta/llama-3.2-3b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='nvidia/nvidia-nemotron-nano-9b-v2', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=True, base_model=None),\n",
       " Model(id='meta/llama-3.2-1b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='moonshotai/kimi-k2-instruct-0905', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='qwen/qwen3-next-80b-a3b-thinking', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=True, base_model=None),\n",
       " Model(id='meta/llama-3.3-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='microsoft/phi-4-mini-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=False, base_model=None),\n",
       " Model(id='ibm/granite-3.3-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=True, base_model=None),\n",
       " Model(id='nv-mistralai/mistral-nemo-12b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='moonshotai/kimi-k2-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='meta/llama-3.1-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='nvidia/llama-3.3-nemotron-super-49b-v1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=True, base_model=None),\n",
       " Model(id='meta/llama-3.1-405b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='openai/gpt-oss-120b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, supports_thinking=False, base_model=None),\n",
       " Model(id='mistralai/mistral-small-3.1-24b-instruct-2503', model_type='vlm', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=False, supports_thinking=False, base_model=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models for tool calling\n",
    "[model for model in ChatNVIDIA.get_available_models() if model.supports_tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33618d9-8b16-4d36-b128-1eeb17e15a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to get current weather for a city\n",
    "    \"\"\"\n",
    "    url = f\"https://goweather.xyz/v2/weather/{query}\"\n",
    "    response = requests.get(url)\n",
    "    temperature = response.json().get(\"temperature\")\n",
    "    if temperature:\n",
    "        return f\"Temperature : {temperature}\"\n",
    "    return \"No data found.\"\n",
    "\n",
    "tools = [get_weather]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2757f-c60d-400a-a091-8860bed68ace",
   "metadata": {},
   "source": [
    "# Define Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ccb639-a5a8-4dfd-8c10-888eb6e3a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful AI assistant. Use tools when they are useful, especially for factual questions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03883e5-dad2-4f7e-8015-ab4947d8b2a0",
   "metadata": {},
   "source": [
    "# Run Agent and Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4336a22-9ce0-4edc-b70b-c0391939fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in SF?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf2524f8-407a-4e5c-b34a-d05fae104149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What's the weather in SF?\", additional_kwargs={}, response_metadata={}, id='53be0302-7f88-4cda-b372-0570a6101799'),\n",
       " AIMessage(content='None', additional_kwargs={'tool_calls': [{'id': 'EhG6fPcSR', 'type': 'function', 'function': {'name': 'get_weather', 'arguments': '{\"query\": \"SF\"}'}}]}, response_metadata={'role': 'assistant', 'content': 'None', 'tool_calls': [{'id': 'EhG6fPcSR', 'type': 'function', 'function': {'name': 'get_weather', 'arguments': '{\"query\": \"SF\"}'}}], 'token_usage': {'prompt_tokens': 101, 'total_tokens': 123, 'completion_tokens': 22}, 'finish_reason': 'tool_calls', 'model_name': 'nvidia/llama-3.1-nemotron-nano-4b-v1.1'}, id='lc_run--2715ab5a-db2a-4957-99b2-b126a9f97f5e-0', tool_calls=[{'name': 'get_weather', 'args': {'query': 'SF'}, 'id': 'EhG6fPcSR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 101, 'output_tokens': 22, 'total_tokens': 123}, role='assistant'),\n",
       " ToolMessage(content='Temperature : 5 °C', name='get_weather', id='3a0efa37-c77f-46f5-b645-8fdd198b2da9', tool_call_id='EhG6fPcSR'),\n",
       " AIMessage(content='The current temperature in San Francisco is 5 °C. Stay warm!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'The current temperature in San Francisco is 5 °C. Stay warm!', 'token_usage': {'prompt_tokens': 172, 'total_tokens': 187, 'completion_tokens': 15}, 'finish_reason': 'stop', 'model_name': 'nvidia/llama-3.1-nemotron-nano-4b-v1.1'}, id='lc_run--c6ded72a-cc73-4032-9702-ccf0ac5d7a27-0', usage_metadata={'input_tokens': 172, 'output_tokens': 15, 'total_tokens': 187}, role='assistant')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13bc470f-2bfb-4a3b-adc3-8c019cf695df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current temperature in San Francisco is 5 °C. Stay warm!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'The current temperature in San Francisco is 5 °C. Stay warm!', 'token_usage': {'prompt_tokens': 172, 'total_tokens': 187, 'completion_tokens': 15}, 'finish_reason': 'stop', 'model_name': 'nvidia/llama-3.1-nemotron-nano-4b-v1.1'}, id='lc_run--c6ded72a-cc73-4032-9702-ccf0ac5d7a27-0', usage_metadata={'input_tokens': 172, 'output_tokens': 15, 'total_tokens': 187}, role='assistant')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc659aa-3901-427e-a273-ff1f8064b61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
